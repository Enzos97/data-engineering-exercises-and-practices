# Ejercicio 11 - PrÃ¡ctica Titanic: NiFi + Airflow + Hive

Este ejercicio integra **Apache NiFi** para flujo de ingesta de datos, **Apache Airflow** para procesamiento y transformaciÃ³n con Pandas, y **Apache Hive** para almacenamiento y anÃ¡lisis SQL de datos del Titanic.

## ğŸ¯ Objetivos

- Crear script bash para descarga automatizada de datos
- Implementar flujo de ingesta completo con Apache NiFi
- Procesar y transformar datos con Pandas en Airflow
- Almacenar datos estructurados en Hive
- Realizar anÃ¡lisis de negocio con SQL

## ğŸ“‹ Ejercicios Incluidos

### 1ï¸âƒ£ **Script Bash - Descarga de Titanic.csv**
- Crear script de descarga desde S3
- Ejecutar en contenedor NiFi
- Verificar archivo descargado

### 2ï¸âƒ£ **PreparaciÃ³n de Directorios**
- Crear directorios necesarios en NiFi
- Configurar archivos de Hadoop (core-site.xml, hdfs-site.xml)
- Preparar directorio en HDFS

### 3ï¸âƒ£ **Flujo NiFi - GetFile (Origen)**
- Configurar procesador GetFile
- Leer desde `/home/nifi/ingest`
- Pasar archivo al siguiente procesador

### 4ï¸âƒ£ **Flujo NiFi - PutFile (Bucket)**
- Mover archivo a `/home/nifi/bucket`
- Configurar resoluciÃ³n de conflictos

### 5ï¸âƒ£ **Flujo NiFi - GetFile (Bucket)**
- Leer desde bucket intermedio
- Preparar para ingesta a HDFS

### 6ï¸âƒ£ **Flujo NiFi - PutHDFS**
- Configurar conexiÃ³n a HDFS
- Ingestar archivo a `/nifi`
- Verificar en HDFS

### 7ï¸âƒ£ **Pipeline Airflow con Transformaciones**
- Crear tabla en Hive
- Desarrollar DAG de Airflow
- Aplicar transformaciones con Pandas:
  - Remover columnas SibSp y Parch
  - Rellenar edad con promedios por gÃ©nero
  - Reemplazar Cabin nulo con 0
- Cargar datos procesados en Hive

### 8ï¸âƒ£ **AnÃ¡lisis de Negocio con Hive**
- Sobrevivientes por gÃ©nero
- Sobrevivientes por clase
- Persona de mayor edad que sobreviviÃ³
- Persona mÃ¡s joven que sobreviviÃ³

## ğŸ“ Estructura del Proyecto

```
ejercicio-11-practica-titanic-nifi-airflow-hive/
â”œâ”€â”€ README.md                    # DocumentaciÃ³n principal
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest.sh               # Script de descarga de titanic.csv
â”‚   â””â”€â”€ README.md               # DocumentaciÃ³n de scripts
â”œâ”€â”€ nifi/
â”‚   â”œâ”€â”€ core-site.xml           # ConfiguraciÃ³n HDFS para NiFi
â”‚   â”œâ”€â”€ hdfs-site.xml           # ConfiguraciÃ³n HDFS para NiFi
â”‚   â””â”€â”€ README.md               # GuÃ­a de configuraciÃ³n NiFi
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ titanic_dag.py          # DAG de procesamiento
â”‚   â””â”€â”€ README.md               # DocumentaciÃ³n de Airflow
â”œâ”€â”€ hive/
â”‚   â”œâ”€â”€ titanic-setup.sql       # Scripts SQL de Hive
â”‚   â””â”€â”€ README.md               # DocumentaciÃ³n de Hive
â”œâ”€â”€ images/                     # Capturas de pantalla
â”‚   â””â”€â”€ README.md               # Ãndice de imÃ¡genes
â””â”€â”€ ejercicios-resueltos.md     # Soluciones completas paso a paso
```

## ğŸš€ TecnologÃ­as Utilizadas

- **Apache NiFi** - OrquestaciÃ³n de flujos de datos
- **Apache Airflow** - Procesamiento y transformaciÃ³n
- **Python Pandas** - ManipulaciÃ³n de datos
- **Apache Hive** - Data warehouse y consultas SQL
- **HDFS** - Sistema de archivos distribuido
- **Bash Scripting** - AutomatizaciÃ³n de descargas
- **CSV** - Formato de datos

## ğŸ“Š Dataset Utilizado

- **Fuente**: Titanic Dataset
- **URL**: https://data-engineer-edvai-public.s3.amazonaws.com/titanic.csv
- **Registros**: 891 pasajeros
- **DescripciÃ³n**: Datos de pasajeros del Titanic incluyendo supervivencia, clase, edad, gÃ©nero, etc.
- **Diccionario**: https://choens.github.io/titanic/workshops/regression/data-dictionary/

### Campos del Dataset

| Campo | Tipo | DescripciÃ³n |
|-------|------|-------------|
| PassengerId | INT | ID Ãºnico del pasajero |
| Survived | INT | 0 = No, 1 = SÃ­ |
| Pclass | INT | Clase del ticket (1 = 1ra, 2 = 2da, 3 = 3ra) |
| Name | STRING | Nombre del pasajero |
| Sex | STRING | GÃ©nero (male/female) |
| Age | FLOAT | Edad en aÃ±os |
| SibSp | INT | # de hermanos/cÃ³nyuges a bordo |
| Parch | INT | # de padres/hijos a bordo |
| Ticket | STRING | NÃºmero de ticket |
| Fare | FLOAT | Tarifa del pasajero |
| Cabin | STRING | NÃºmero de cabina |
| Embarked | STRING | Puerto de embarque (C/Q/S) |

## ğŸ”§ Requisitos Previos

- Contenedor NiFi ejecutÃ¡ndose
- Contenedor Hadoop ejecutÃ¡ndose
- Apache Hive configurado y funcionando
- Apache Airflow instalado y configurado
- Python con Pandas instalado
- Acceso a internet para descarga de datos

## ğŸš€ Pipeline Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         1. DESCARGA (Script Bash en NiFi)                    â”‚
â”‚              titanic.csv â†’ /home/nifi/ingest                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         2-6. FLUJO NIFI (Movimiento de Archivos)            â”‚
â”‚  GetFile â†’ PutFile â†’ GetFile â†’ PutHDFS â†’ HDFS:/nifi        â”‚
â”‚  (ingest)  (bucket)  (bucket)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         7. PROCESAMIENTO (Airflow + Pandas)                  â”‚
â”‚  â€¢ Descarga desde HDFS                                       â”‚
â”‚  â€¢ Remover columnas (SibSp, Parch)                          â”‚
â”‚  â€¢ Rellenar edad con promedios por gÃ©nero                   â”‚
â”‚  â€¢ Cabin nulo â†’ 0                                           â”‚
â”‚  â€¢ Carga en Hive                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         8. ANÃLISIS (Hive SQL)                               â”‚
â”‚  â€¢ Sobrevivientes por gÃ©nero                                 â”‚
â”‚  â€¢ Sobrevivientes por clase                                  â”‚
â”‚  â€¢ Mayor y menor edad sobrevivientes                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“– GuÃ­as de Uso

### EjecuciÃ³n RÃ¡pida

1. **Descargar datos**:
```bash
docker exec -it nifi bash
/home/nifi/ingest/ingest.sh
```

2. **Configurar flujo NiFi**:
   - Acceder a https://localhost:8443/nifi
   - Crear procesadores segÃºn documentaciÃ³n
   - Ejecutar flujo

3. **Crear tabla Hive**:
```bash
docker exec -it edvai_hadoop bash
hive -f /home/hadoop/hive/titanic-setup.sql
```

4. **Ejecutar DAG Airflow**:
```bash
airflow dags trigger titanic_processing_dag
```

5. **Ejecutar consultas**:
```bash
hive -f /home/hadoop/hive/titanic-setup.sql
```

## ğŸ¯ Resultados Esperados

### Datos Procesados
- **Total registros**: 891 pasajeros
- **Columnas originales**: 12
- **Columnas finales**: 10 (removidas SibSp y Parch)
- **Valores nulos tratados**: Edad y Cabin

### AnÃ¡lisis de Negocio

**Sobrevivientes por GÃ©nero**:
- Mujeres: 233 (74.20% de supervivencia)
- Hombres: 109 (18.89% de supervivencia)

**Sobrevivientes por Clase**:
- 1ra clase: 136
- 2da clase: 87
- 3ra clase: 119

**Edades Extremas**:
- Mayor: Barkworth Mr. Algernon Henry Wilson (80 aÃ±os)
- Menor: Thomas Master. Assad Alexander (0.42 aÃ±os)

## ğŸ“ Notas Importantes

### ConfiguraciÃ³n de NiFi

Los archivos `core-site.xml` y `hdfs-site.xml` deben estar en `/home/nifi/hadoop/`:

```xml
<!-- core-site.xml -->
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://172.17.0.2:9000</value>
</property>

<!-- hdfs-site.xml -->
<property>
    <name>dfs.replication</name>
    <value>1</value>
</property>
```

### Permisos HDFS

Asegurarse de dar permisos al directorio:
```bash
hdfs dfs -chmod 777 /nifi
```

### Transformaciones

- **Edad**: Se calcula promedio por gÃ©nero y se rellena
- **Cabin**: Valores nulos se convierten a 0
- **Name**: Se eliminan comas para evitar conflictos con CSV

## ğŸ”— Referencias

- [Apache NiFi Documentation](https://nifi.apache.org/docs.html)
- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Titanic Dataset Dictionary](https://choens.github.io/titanic/workshops/regression/data-dictionary/)

## ğŸ“§ Contacto

Para consultas o problemas, contactar al equipo de Data Engineering.

---

**Autor**: Edvai Team  
**Fecha**: 2025-11-20  
**VersiÃ³n**: 1.0

