# ğŸ“Š Data Engineering Exercises and Practices

Este repositorio contiene ejercicios prÃ¡cticos de **ingenierÃ­a de datos** enfocados en la ingesta de datos usando **Hadoop**, **HDFS** y **Sqoop**. Incluye scripts automatizados para diferentes escenarios de ingesta.

---

## ğŸ¯ Objetivos

- Practicar la ingesta de datos desde fuentes externas hacia HDFS
- Automatizar procesos de ETL usando scripts bash
- Conectar bases de datos relacionales (PostgreSQL) con Hadoop usando Sqoop
- Gestionar archivos temporales y limpieza de datos

---

## ğŸ“ Estructura del Repositorio

```
data-engineering-exercises-and-practices/
â”œâ”€â”€ ejercicio-3-practica-de-ingest-local/     # Ingesta desde fuentes externas
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ landing.sh                        # Script de ingesta local
â”‚   â”œâ”€â”€ images/                               # Capturas de pantalla
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ ejercicio-4-practica-ingest-sqoop/        # Ingesta desde PostgreSQL
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ sqoop.sh                          # Script de comandos Sqoop
â”‚   â””â”€â”€ README.md
â””â”€â”€ README.md                                 # Este archivo
```

---

## ğŸš€ Ejercicios Incluidos

### 1ï¸âƒ£ **Ejercicio 3: Ingesta Local con Hadoop**

**DescripciÃ³n:** Descarga un archivo CSV desde GitHub, lo mueve a HDFS y limpia archivos temporales.

**CaracterÃ­sticas:**
- âœ… Descarga automÃ¡tica desde GitHub
- âœ… GestiÃ³n de directorios temporales
- âœ… Subida a HDFS
- âœ… Limpieza automÃ¡tica de archivos

**Archivo:** `ejercicio-3-practica-de-ingest-local/scripts/landing.sh`

### 2ï¸âƒ£ **Ejercicio 4: Ingesta con Sqoop**

**DescripciÃ³n:** Conecta PostgreSQL con Hadoop usando Sqoop para importar datos.

**CaracterÃ­sticas:**
- âœ… ConexiÃ³n JDBC con PostgreSQL
- âœ… Listado de tablas
- âœ… Consultas SQL directas
- âœ… ImportaciÃ³n completa y filtrada
- âœ… Formato Parquet

**Archivo:** `ejercicio-4-practica-ingest-sqoop/scripts/sqoop.sh`

---

## ğŸ”§ Requisitos Previos

### Entorno de Desarrollo
- **Docker** con contenedores de Hadoop y PostgreSQL
- **Bash** para ejecutar scripts
- Acceso a terminal del contenedor Hadoop

### Contenedores Necesarios
```bash
# Contenedor Hadoop
docker exec -it edvai_hadoop bash
su hadoop

# Verificar PostgreSQL
docker inspect edvai_postgres
```

---

## ğŸ“‹ CÃ³mo Ejecutar

### Ejercicio 3: Ingesta Local
```bash
# 1. Navegar al directorio
cd ejercicio-3-practica-de-ingest-local/scripts/

# 2. Dar permisos de ejecuciÃ³n
chmod +x landing.sh

# 3. Ejecutar el script
./landing.sh

# 4. Verificar en HDFS
hdfs dfs -ls /ingest
```

### Ejercicio 4: Ingesta con Sqoop
```bash
# 1. Navegar al directorio
cd ejercicio-4-practica-ingest-sqoop/scripts/

# 2. Dar permisos de ejecuciÃ³n
chmod +x sqoop.sh

# 3. Ejecutar el script
./sqoop.sh
```

---

## ğŸ“Š Datos Utilizados

### Ejercicio 3
- **Fuente:** [starwars.csv](https://github.com/fpineyro/homework-0/blob/master/starwars.csv)
- **Destino:** `/ingest/` en HDFS
- **Formato:** CSV

### Ejercicio 4
- **Fuente:** Base de datos Northwind (PostgreSQL)
- **Tabla:** `region`
- **Destino:** `/sqoop/ingest/` en HDFS
- **Formato:** Parquet

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Hadoop** - Framework de procesamiento distribuido
- **HDFS** - Sistema de archivos distribuido
- **Sqoop** - Herramienta de transferencia de datos
- **PostgreSQL** - Base de datos relacional
- **Bash** - Scripting y automatizaciÃ³n
- **Docker** - Contenedores

---

## ğŸ“ Notas Importantes

- Los scripts incluyen manejo de errores y mensajes informativos
- Se realizan limpiezas automÃ¡ticas de archivos temporales
- Los directorios se crean automÃ¡ticamente si no existen
- Las conexiones JDBC requieren configuraciÃ³n de red entre contenedores

---

## ğŸ‘¨â€ğŸ’» Autor

**Enzo** - PrÃ¡cticas de Data Engineering

---

## ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n de Hadoop](https://hadoop.apache.org/docs/)
- [GuÃ­a de Sqoop](https://sqoop.apache.org/docs/)
- [Docker para Data Engineering](https://docs.docker.com/)